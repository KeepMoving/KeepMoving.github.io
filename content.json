{"meta":{"title":"互联网实践者","subtitle":"阅读使人充实，写作使人精确","description":null,"author":"Wayne Wang","url":"http://yoursite.com"},"pages":[{"title":"my first page","date":"2019-02-09T08:53:55.000Z","updated":"2019-02-09T08:53:55.524Z","comments":true,"path":"my-first-page/index.html","permalink":"http://yoursite.com/my-first-page/index.html","excerpt":"","text":""}],"posts":[{"title":"定位springboot启动异常","slug":"定位springboot启动异常","date":"2019-02-27T13:40:54.000Z","updated":"2019-03-02T12:31:44.318Z","comments":true,"path":"2019/02/27/定位springboot启动异常/","link":"","permalink":"http://yoursite.com/2019/02/27/定位springboot启动异常/","excerpt":"最近在springboot中集成kafka，然后启动的时候抛出异常该如何定位问题？基本思路是用远程debug（也可以在本地启动）+ Java Exception Breakpoints","text":"最近在springboot中集成kafka，然后启动的时候抛出异常该如何定位问题？基本思路是用远程debug（也可以在本地启动）+ Java Exception Breakpoints上图中，抛出了TypeNotPresentExceptionProxy的异常，把断点打到TypeNotPresentExceptionProxy的构造函数，可以截获到如下信息：看的出来是因为PropertyPlaceholderAutoConfiguration这个类的缺失。知道了异常的原因，下一步就是定位在哪里抛出异常，通过Java Exception Breakpoints。在java的debug视图中，添加Java Exception Breakpoints，指定具体异常是ArrayStoreException,如图:然后启动springboot工程，等抛出ArrayStoreException异常前，就会定位到具体的代码，如下图从异常信息可以看到发生异常的类是KafkaBinderConfiguration可以看到KafkaBinderConfiguration引用的是springboot1.x版本的PropertyPlaceholderAutoConfiguration，包路径是org.springframework.boot.autoconfigure.PropertyPlaceholderAutoConfiguration，而我们项目用的springboot是2.x，这个类是在org.springframework.boot.autoconfigure.context下面。因为springboot在升级2.x版本后，改动了一些包路径，所以导致启动异常","categories":[],"tags":[]},{"title":"自己动手搭建kafka及源码阅读环境","slug":"自己动手搭建kafka及源码阅读环境","date":"2019-02-24T06:55:44.000Z","updated":"2019-03-04T06:48:12.240Z","comments":true,"path":"2019/02/24/自己动手搭建kafka及源码阅读环境/","link":"","permalink":"http://yoursite.com/2019/02/24/自己动手搭建kafka及源码阅读环境/","excerpt":"","text":"搭建kafka源码阅读环境1、配置本地的jdk环境及IDE，jdk最好是1.8以上2、下载并配置gradle下载地址 http://services.gradle.org/distributions/选择gradle版本的时候，要注意配合你所下载的kafka版本我所在项目使用的kafka版本是0.9.0.1，然后我下载了0.9.x版本的kafka源码，同时下载最新版的gradle，但是本地构建的时候，一直报如下错误以及如下的错误1234Details: groovy.lang.MissingPropertyException: Could not get unknown property &apos;classesDir&apos; for main classes of type org.gradle.api.internal.tasks.DefaultSourceSetOutput.&lt;/i&gt;Warning:&lt;i&gt;&lt;b&gt;root project &apos;kafka-0.9.0.1-src&apos;: Unable to resolve additional project configuration.&lt;/b&gt;Details: groovy.lang.MissingPropertyException: Could not get unknown property &apos;projectConfiguration&apos; for DefaultProjectDependency&#123;dependencyProject=&apos;project &apos;:clients&apos;&apos;, configuration=&apos;default&apos;&#125; of type org.gradle.api.internal.artifacts.dependencies.DefaultProjectDependency.&lt;/i&gt; 这都是因为gradle和kafka源码版本不兼容。为了确定哪个版本的gradle和kafka版本兼容，我在kafka源码中全局搜了一下gradle然后我猜测0.9.0.1版本的源码需要配合2.2.1版本的gradle，安装相应的grade证实，确实是这样的安装过程很简单，下载gradle，解压到本地目录，设置系统环境GRADLE_HOME：D:\\Program Files\\gradle-2.2.1PATH：%GRADLE_HOME%\\bin在IDE中设置gradle环境Gradle home: D:/Program Files/gradle-2.2.1JDK选择1.8 3、安装scala插件因为kafka部分源码是用scala编写的，比如Consumer类的父类ShutdownableThread，所以IDE需要继承scala插件，否则会报编译错误具体步骤是在settings-&gt;Plugins-&gt;Browse Repositories中搜索scala插件，点击安装即可 4、导入kafka源码点击import project，选择kafka源码目录，然后选择gradle项目导入导入后，打卡ide的gradle视图，选择refresh项目，即可 部署kafka从kafka官网上选择一个版本官网地址:http://kafka.apache.org/downloads 下载kafka运行包 curl -L -O https://archive.apache.org/dist/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz 解压 tar zxvf kafka_2.11-0.9.0.1.tgz 进入config/server.properties，主要配置三个参数：broker.id、log.dir、zookeeper.connect 启动kafka，执行bin/kafka-server-start.sh config/server.properties &amp; 如果报以下错误 是因为jdk版本不兼容，要求jdk版本在1.7以上 可以在bin/kafka-run-class.sh中指定jdk版本，如图 进入kafka目录，执行bin/kafka-server-start.sh config/server.properties &amp;如果启动报如下错误，是因为config/server.properties中的broker.id重复，重新指定一个即可","categories":[],"tags":[]},{"title":"spring的事务切面（下）","slug":"spring的事务切面（下）","date":"2019-02-23T06:29:48.000Z","updated":"2019-03-02T12:42:20.374Z","comments":true,"path":"2019/02/23/spring的事务切面（下）/","link":"","permalink":"http://yoursite.com/2019/02/23/spring的事务切面（下）/","excerpt":"事务处理拦截器的配置和创建过程建立事务处理对象的时序图","text":"事务处理拦截器的配置和创建过程建立事务处理对象的时序图Spring为声明式事务处理的实现所作的一些准备工作：包括为AOP配置基础设施，这些基础设施包括设置拦截器TransactionInterceptor、通知器DefaultPointcutAdvisor或TransactionAttributeSourceAdvisor。同时，在TransactionProxyFactoryBean的实现中，还可以看到注入进来的PlatformTransactionManager和事务处理属性TransactionAttribute等。这个拦截器TransactionInterceptor通过AOP发挥作用，通过这个拦截器的实现，Spring封装了事务处理实现。依赖注入的PlatformTransactionManager。通过依赖注入的事务属性以Properties的形式出现，把从BeanDefinition中读到的事务管理的属性信息注入到TransactionInteceptor中。这里创建Spring Aop对事务的Advisor，如果pointcut不为null，则使用默认的通知器,并为通知器配置事务处理拦截器。如果没有配置pointcut，使用TransactionAttributeSourceAdvisor作为通知器，并为通知器设置TransactionInterceptor作为拦截器。TransactionProxyFactoryBean的继承关系从对createMainInterceptor方法的调用分析中可以看到，这个createMainInterceptor方法在IOC容器完成Bean的依赖注入时，通过initializeBean方法被调用。具体调用过程如下图.createMainInterceptor方法的调用关系TransactionProxyFactoryBean通过继承AbstractSingletonProxyFactoryBean，使用afterPropertiesSet()方法，在方法中使用ProxyFactory完成AOP的基本功能.","categories":[],"tags":[]},{"title":"spring的事务切面（中）","slug":"spring的事务切面（中）","date":"2019-02-23T06:28:14.000Z","updated":"2019-03-02T12:47:27.639Z","comments":true,"path":"2019/02/23/spring的事务切面（中）/","link":"","permalink":"http://yoursite.com/2019/02/23/spring的事务切面（中）/","excerpt":"在创建当前线程时，线程中已经有事务存在了 先来复习以下事务的传播特性。 事务的7种传播特性Propagation （事务的传播属性）Propagation：key属性确定代理应该给哪个方法增加事务行为。这样的属性最重要的部份是传播行为。有以下选项可供使用：PROPAGATION_REQUIRED – 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。PROPAGATION_SUPPORTS – 支持当前事务，如果当前没有事务，就以非事务方式执行。PROPAGATION_MANDATORY – 支持当前事务，如果当前没有事务，就抛出异常。PROPAGATION_REQUIRES_NEW – 新建事务，如果当前存在事务，把当前事务挂起。PROPAGATION_NOT_SUPPORTED – 以非事务方式执行操作，如果当前存在事务，就把当前### 事务挂起。PROPAGATION_NEVER – 以非事务方式执行，如果当前存在事务，则抛出异常。PROPAGATION_NESTED – 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。","text":"在创建当前线程时，线程中已经有事务存在了 先来复习以下事务的传播特性。 事务的7种传播特性Propagation （事务的传播属性）Propagation：key属性确定代理应该给哪个方法增加事务行为。这样的属性最重要的部份是传播行为。有以下选项可供使用：PROPAGATION_REQUIRED – 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。PROPAGATION_SUPPORTS – 支持当前事务，如果当前没有事务，就以非事务方式执行。PROPAGATION_MANDATORY – 支持当前事务，如果当前没有事务，就抛出异常。PROPAGATION_REQUIRES_NEW – 新建事务，如果当前存在事务，把当前事务挂起。PROPAGATION_NOT_SUPPORTED – 以非事务方式执行操作，如果当前存在事务，就把当前### 事务挂起。PROPAGATION_NEVER – 以非事务方式执行，如果当前存在事务，则抛出异常。PROPAGATION_NESTED – 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 1： PROPAGATION_REQUIRED加入当前正要执行的事务不在另外一个事务里，那么就起一个新的事务比如说，ServiceB.methodB的事务级别定义为PROPAGATION_REQUIRED, 那么由于执行ServiceA.methodA的时候，ServiceA.methodA已经起了事务，这时调用ServiceB.methodB，ServiceB.methodB看到自己已经运行在ServiceA.methodA的事务内部，就不再起新的事务。而假如ServiceA.methodA运行的时候发现自己没有在事务中，他就会为自己分配一个事务。这样，在ServiceA.methodA或者在ServiceB.methodB内的任何地方出现异常，事务都会被回滚。即使ServiceB.methodB的事务已经被提交，但是ServiceA.methodA在接下来fail要回滚，ServiceB.methodB也要回滚2： PROPAGATION_SUPPORTS如果当前在事务中，即以事务的形式运行，如果当前不再一个事务中，那么就以非事务的形式运行3： PROPAGATION_MANDATORY必须在一个事务中运行。也就是说，他只能被一个父事务调用。否则，他就要抛出异常4： PROPAGATION_REQUIRES_NEW比如我们设计ServiceA.methodA的事务级别为PROPAGATION_REQUIRED，ServiceB.methodB的事务级别为PROPAGATION_REQUIRES_NEW，那么当执行到ServiceB.methodB的时候，ServiceA.methodA所在的事务就会挂起，ServiceB.methodB会起一个新的事务，等待ServiceB.methodB的事务完成以后，他才继续执行。他与PROPAGATION_REQUIRED 的事务区别在于事务的回滚程度了。因为ServiceB.methodB是新起一个事务，那么就是存在两个不同的事务。如果ServiceB.methodB已经提交，那么ServiceA.methodA失败回滚，ServiceB.methodB是不会回滚的。如果ServiceB.methodB失败回滚，如果他抛出的异常被ServiceA.methodA捕获，ServiceA.methodA事务仍然可能提交。5： PROPAGATION_NOT_SUPPORTED当前不支持事务。比如ServiceA.methodA的事务级别是PROPAGATION_REQUIRED ，而ServiceB.methodB的事务级别是PROPAGATION_NOT_SUPPORTED ，那么当执行到ServiceB.methodB时，ServiceA.methodA的事务挂起，而他以非事务的状态运行完，再继续ServiceA.methodA的事务。6： PROPAGATION_NEVER不能在事务中运行。假设ServiceA.methodA的事务级别是PROPAGATION_REQUIRED， 而ServiceB.methodB的事务级别是PROPAGATION_NEVER ，那么ServiceB.methodB就要抛出异常了。7： PROPAGATION_NESTED理解Nested的关键是savepoint。他与PROPAGATION_REQUIRES_NEW的区别是，PROPAGATION_REQUIRES_NEW另起一个事务，将会与他的父事务相互独立，而Nested的事务和他的父事务是相依的，他的提交是要等和他的父事务一块提交的。也就是说，如果父事务最后回滚，他也要回滚的。而Nested事务的好处是他有一个savepoint。在创建当前事务时，线程中已经有事务存在了。这种情况同样需要处理，在声明式事务处理中，在当前线程调用事务方法的时候，就会考虑事务的创建处理，这个处理在方法handleExistingTransaction中完成的。408.如果当前线程已有事务存在，且当前事务的传播属性设置是never，那么抛出异常，说明这种情况是有问题，Spring无法处理当前的事务创建。413.如果当前事务的配置属性是PROPAGATION_NOT_SUPPORTED,同时当前线程已经存在事务了，那么将事务挂起。419.注意PROPAGATION_NOT_SUPPORTED时候的参数，transaction为null, newTransaction为false,意味着事务方法不需要放在事务环境中执行，同时挂起事务的信息记录也保存在TransactionStatus中，这里包括了进程ThreadLocal对事务信息的记录423.如果当前事务的配置属性是PROPAGATION_REQUIRES_NEW，创建新事务，同时把当前线程中存在的事务挂起。与创建全新事务的过程类似，区别在于，在创建全新事务时不用考虑已有事务的挂起，但在这里，需要考虑已有事务的挂起处理。将事务挂起的目的当然是为了在当前事务执行完毕后再将原事务还原。447.嵌套事务的创建457.如果可以使用保存点的方式控制事务回滚，那么在嵌入式事务的建立初始建立保存点，作为异常处理的回滚。466.有些情况是不能使用保存点操作，比如JTA，那么建立新事务，处理方法和PROPAGATION_REQUIRES_NEW相同，而一旦出现异常，则由Spring的事务异常处理机制去完成后续操作。482.这里判断在当前事务方法中的属性配置与已有事务的属性配置是否一致，如果不一致，那么不执行事务方法并抛出异常。501.返回TransactionStatus，注意第三个参数false代表当前事务方法没有使用新的事务。事务的挂起 事务的挂起牵扯到线程与事务处理信息的保存。577.返回的SuspendedResourceHolder会作为参数传给TransactionStatus582.把挂起事务的处理交给具体事务处理器去完成，如果具体的事务处理器不支持事务挂起，那么默认抛出异常TransactionSuspensionNotSupportedException585.这里在线程中保存与事务处理相关的信息，并重置线程中相关的ThreadLocal变量597.方法失败，而初始的事务依然存在基于以上内容，就可以完成声明式事务处理的创建了。事务的提交 事务提交的入口调用在TransactionInteceptor的invoke方法中实现，如commitTransactionAfterReturning(txInfo); 在这个调用中，我们看到的txInfo是TransactionInfo对象，这个参数TransactionInfo对象是创建事务时生成的。同时，Spring的事务管理框架生成的TransactionStatus对象就包含在TransactionInfo对象中。这个commitTransactionAfterReturning方法通过调用事务处理器来完成事务的提交。 在AbstractPlatformTransactionManger中也有一个模板方法支持具体的事务处理器对事务提交的实现。在AbstractPlatformTransactionManager中，这个模板方法的实现与前面的getTransaction类似，如下图707.在TransactionStatus中标识事务已经结束713.如果事务处理过程中发生了异常，调用回滚717.这里处理回滚727.抛出UnexpectedRollbackException异常734.处理提交的入口747.事务提交的准备工作由具体的事务处理器来完成755.这里是嵌套事务的处理761.下面对根据当前线程中保存的事务状态进行处理，如果当前的事务是一个新事务，调用具体事务处理器的完成提交；如果当前所持有的事务不是一个新事务，则不提交，由已经存在的事务来完成提交。807.触发afterCommit()回滚可以看到，事务提交的准备都是由具体的事务处理器来实现的。当然，对这些事务提交的处理，需要通过对TransactionStatus保存的事务处理的相关状态进行判断。提交过程涉及AbstractPlatformTransactionManager中的doCommit和prepareForCommit方法，它们都是抽象方法，都在具体的事务处理器中完成实现。在提交的过程中也并不是直接提交的，而是考虑了诸多的方面，符合提交的条件如下：1.当事务状态中有保存点信息的话不会去提交事务2.当事务非新事务的时候也不会去执行提交事务操作 事务的回滚在对目标方法的执行过程中，一旦出现Throwable就会被引导至此方法处理，但是并不代表所有的Throwable就会被回滚处理。关键就在于txInfo.transactionAttribute.rollBackOn(ex)。当然你可以通过扩展改变，例如@Transactional(propagation= Propagation.REQUIRED,rollbackFor = Exception.class)843.根据TransactionStatus信息进行回滚处理847.嵌套事务的回滚处理851.如果有保存点，也就是当前事务为单独的线程则会退到保存点853.如果当前事务为独立的新事务，则直接回退859.如果当前事务不是独立的事务，那么只能标记状态，等到事务链执行完毕后统一回滚866.由线程中的前一个事务来处理回盾，这里不执行任何操作887.清空记录的资源并将挂起的资源恢复对于回滚逻辑执行结束后，无论回滚是否成功，都必须要做的事情就是事务结束后的收尾工作。事务处理的收尾处理工作包括以下内容： * 设置状态时对事务信息作完成标识以避免重复调用。 * 如果当前事务是新的同步状态，需要将绑定到当前线程的事务信息清除。 * 如果是新事务需要做些清除资源的工作 * 如果在事务执行前有事务挂起，那么当前事务执行结束后需要将挂起事务恢复。351.将数据库连接从当前线程中解除绑定355.释放链接358.恢复数据库连接的自动提交属性360.重置数据库连接370.如果当前事务是独立的新创建的事务，则在事务完成时释放数据库连接 Spring事务处理器的设计与实现以DataSourceTransactionManager为例，在DataSourceTransactionManager中，在事务开始的时候，会调用doBegin方法，首先会得到相对应的Connection，然后可以根据事务设置的需要，对Connection的相关属性进行配置，比如将Connection的autoCommit功能关闭，并对像TimeoutInSeconds这样的事务处理参数进行设置，最后通过TransactionSynchronizationManager来对资源进行绑定。实现DataSourceTransactionManager的时序图 155.这是注入的dataSource220.这里是产生Transaction的地方，为Transaction的创建提供服务。对数据库而言，事务工作是由Connection来完成。这里把数据库的Connection对象放到一个ConnectionHolder中，然后封装到一个DataSourceTransactionObject对象中，在这个封装过程中增加了许多为事务处理服务的控制数据。223.获取与当前线程绑定的数据库Connection，这个Connection在第一个事务开始的地方与线程绑定。这里是判断是否已经存在事务的地方，由ConnectionHolder的isTransactionActive属性来控制。239.这里是处理事务开始的地方。构造transaction,包括设置ConnectionHolder、隔离级别、timeout。如果是新连接，绑定到当前线程。256.设置隔离级别。设置隔离级别的prepareConnectionForTransaction函数用于负责对底层数据库连接的设置，当然，只是包含只读标识和隔离级别的设置。隔离级别最终的控制也是交由connection。262.这里是数据库Connection完成事务处理的重要配置，需要把autoCommit属性关掉，由Spring控制提交。271.设置判断当前线程是否存在事务的依据。279.把当前的数据库Connection和线程绑定 可以说事务是从doBegin()这个函数开始的，因为在这个函数中已经开始尝试了对数据库连接的获取，当然，在获取数据库连接的同时，一些必要的设置也是需要同步设置的。 * 尝试获取连接。当然并不是每次都会获取新的连接，如果当前线程中的connectionHolder已经存在，则没必要再次获取，或者，对于事务同步标识设置为true的需要重新获取连接。 * 设置隔离级别以及只读标志。Spring中确实是针对只读操作做了一些处理，但是核心的实现是设置connection上的readOnly属性。同时，对于隔离级别的控制也是交由connection去控制的。 * 更改默认的提交设置。 * 设置标志位，标识当前连接已经被事务激活。 * 设置过期时间。 * 将connectionHolder绑定到当前线程 306.事务的提交过程307.取得Connection以后，通过Connection进行提交321.事务的回滚过程，使用Connection的rollback方法 上面介绍了使用DataSourceTransactionManager实现事务创建、提交和回滚的过程，基本上与单独使用Connection实现事务处理是一样的，也是通过设置autoCommit属性，调用Connection的commit和rollback方法来完成的。 整体总结：在以上过程中，有几个Spring事务处理的核心类是我们需要关注的。其中包括：TransactionInterceptor——它是使用AOP实现声明式事务处理的拦截器，封装了Spring对声明式事务处理实现的基本过程TransactionAttributeSource和TransactionAttribute——它们封装了对声明式事务处理属性的识别，以及信息的读入和配置。我们看到的TransactionAttribute对象，可以视为对事务处理属性的数据抽象，如果在使用声明式事务处理的时候，应用没有配置这些属性，Spring将为用户提供DefaultTransactionAttribute对象，在这个DefaultTransactionAttribute对象中，提供了默认的事务处理属性设置。 在事务处理过程中，可以看到TransactionInfo和TransactionStatus这两个对象，它们视存放事务处理信息的主要数据对象，它们通过与线程的绑定来实现事务的隔绝性。具体来说，TransactionInfo对象本身就像是一个栈，对应着每一次事务方法的调用，它会保存每一次事务方法调用的事务处理信息。值得注意的是，在TransactionInfo对象中，它持有TransactionStatus对象，这个TransactionStatus是非常重要的。由这个TransactionStatus来掌管事务执行的详细信息，包括具体的事务对象、事务执行状态、事务设置状态等。在事务的创建、启动、提交和回滚的过程中，都需要与这个TransactionStatus对象中的数据打交道。在准备完这些与事务管理有关的数据之后，具体的事务处理是由事务处理器TransactionManager来完成的。在事务处理器完成事务处理的过程中，与具体事务处理器无关的操作都被封装到AbstractionPlatformTransactionManager中实现了。这个抽象的事务处理器为不同的具体事务处理器提供了通用的事务处理模板，它封装了在事务处理过程中，与具体事务处理器无关的公共的事务处理部分。我们在具体的事务处理器(比如DataSourceTransactionManager)的实现中可以看到，最为底层的事务创建、挂起、提交、回滚操作。","categories":[],"tags":[]},{"title":"spring的事务切面（上）","slug":"spring的事务切面（上）","date":"2019-02-23T06:18:38.000Z","updated":"2019-03-02T12:38:42.184Z","comments":true,"path":"2019/02/23/spring的事务切面（上）/","link":"","permalink":"http://yoursite.com/2019/02/23/spring的事务切面（上）/","excerpt":"一个问题在插入操作的事务最后抛出Exception异常，能否插入成功？Spring事务处理的设计概览 Spring的事务处理模板中的类层次接口 真正处理事务的是TransactionInterceptor，PlatformTransactionManager,AbstractionTransactionManager以及DataSourceTransactionManager，其他的类用来读取配置、加载通知以及实现织入。事务处理拦截器的设计与实现TransactionInterceptor类继承自MethodInterceptor，所以调用该类是从其invoke方法开始的。这个invoke()方法是Proxy代理对象的回调方法，在调用Proxy对象的代理方法时触发这个回调。在事务处理拦截器TransactionInterceptor中，invoke方法的实现如下图。可以看到，其过程时，首先获得调用方法的事务处理配置；在得到事务处理配置之后，会取得配置的PlatformTransactionManger，由这个事务处理器来实现事务的创建、提交、回滚操作。PlatformTransactionManger事务处理器是在Ioc容器中配置的，比如大家已经很熟悉的DataSourceTransactionManger和HibernateTransactionManager。有了这一系列的具体事务处理器的配置，在Spring事务处理模块的统一管理下，由这些具体的事务处理器来完成事务的创建、提交、回滚等底层的事务操作。","text":"一个问题在插入操作的事务最后抛出Exception异常，能否插入成功？Spring事务处理的设计概览 Spring的事务处理模板中的类层次接口 真正处理事务的是TransactionInterceptor，PlatformTransactionManager,AbstractionTransactionManager以及DataSourceTransactionManager，其他的类用来读取配置、加载通知以及实现织入。事务处理拦截器的设计与实现TransactionInterceptor类继承自MethodInterceptor，所以调用该类是从其invoke方法开始的。这个invoke()方法是Proxy代理对象的回调方法，在调用Proxy对象的代理方法时触发这个回调。在事务处理拦截器TransactionInterceptor中，invoke方法的实现如下图。可以看到，其过程时，首先获得调用方法的事务处理配置；在得到事务处理配置之后，会取得配置的PlatformTransactionManger，由这个事务处理器来实现事务的创建、提交、回滚操作。PlatformTransactionManger事务处理器是在Ioc容器中配置的，比如大家已经很熟悉的DataSourceTransactionManger和HibernateTransactionManager。有了这一系列的具体事务处理器的配置，在Spring事务处理模块的统一管理下，由这些具体的事务处理器来完成事务的创建、提交、回滚等底层的事务操作。第一步是得到代理的目标对象，并将事务属性传递给目标对象。采用非回调的方法来对事务进行提交271.读取事务的配置属性，通过TransactionAttributeSource对象取得272.根据TransactionProxyFactoryBean的配置信息获得具体的事务处理器273.构造方法唯一标识（类.方法 如service.impl.UserServiceImpl.save）275.这里区分不同类型的PlatformTransactionManger，因为他们的调用方式不同，对CallbackPreferringPlatformTransactionManger来说，需要回调函数来实现事务的创建和提交；对于非CallbackPreferringPlatformTransactionManger来说，不需要通过回调函数来实现事务的和提交，像DataSourceTransactionManger就不是CallbackPreferringPlatformTransactionManger，不需要通过回调的方式来使用。277.这里创建事务，同时把创建事务过程中得到的信息放到TransactionInfo中去，TransactionInfo是保存当前事务状态的对象。282.这里的调用使处理沿着拦截器链进行，使最后目标对象的方法得到调用。286.如果在事务处理方法调用中出现了异常，事务处理如何进行需要根据具体的情况考虑回滚或者提交。Spring默认只对RuntimeException以及Error执行回滚290.这里把与线程绑定的TransactionInfo设置为oldTransactionInfo292.这里通过事务处理器来对事务进行提交。采用回调的方法来使用事务处理器。312.RuntimeException会导致事务回滚321.正常的返回，导致事务提交流程梳理：在调用代理的事务方法时，因为前面已经完成了一系列AOP配置，对事务方法的调用，最终启动TransactionInterceptor拦截器的invoke方法。在这个方法中，首先会读取该事务方法的事务属性配置，然后根据事务属性配置以及具体事务处理器的配置来决定采用哪一个事务处理器，这个事务处理器实际上是一个PlatformTransactionManger。在决定好具体的事务处理器之后，会根据事务的运行情况和事务配置来决定是不是需要创建新的事务。对于Spring而言，事务的管理实际上是通过一个TransactionInfo对象来完成的，在该对象中，封装了事务对象和事务处理的状态信息，这是事务处理的抽象。在这一步完成之后，会对拦截器链进行处理，因为有可能在该事务对象中还配置了除事务处理AOP之外的其他拦截器。在结束对拦截器链处理之后，会对TransactionInfo中的信息进行更新，以反映最近的事务处理情况，在这个时候，也就是完成了事务提交的准备，通过调用事务处理器PlatformTransactionManger的commitTransactionAfterReturning方法来完成事务的提交。这个提交的处理过程已经封装在PlatformTransactionManger的事务处理器中了，而与具体数据源相关的处理过程，最终委托给相关的具体事务处理器来完成，比如DataSourceTransactionManager、HibernateTransactionManager等。事务提交的时序图在这个invoke()方法的实现中，可以看到整个事务处理在AOP拦截器中实现的全过程。同时，它也是Spring采用AOP封装事务处理和实现声明式事务处理的核心部分。这部分实现，是一个桥梁，它胶合了具体的事务处理和Spring AOP框架，可以看成是一个Spring AOP应用，在这个桥梁搭建完成之后，Spring事务处理的实现就开始了。Spring事务处理的编程式使用（模型）在编程式使用事务处理的过程中，利用DefaultTransactionDefinition对象来持有事务处理属性。同时，在创建事务的过程中得到一个TransactionStatus对象，然后通过直接调用transactionManager的commit()和rollback()方法来完成事务处理。在这个编程式使用事务管理的过程中，没有看到框架特性的使用，非常简单和直接，很好地说明了事务管理的基本实现过程，以及在Spring事务处理实现中涉及一些主要的类，比如TransactionStatus、TransactionManger等，对这些类的使用与声明式事务处理的最终实现是一样的。事务的创建作为声明式事务处理实现的起始点，需要注意TransactionInterceptor拦截器的invoke回调中使用的createTransactionIfNecessary方法，这个方法是在TransactionIntercepor的基类TransactionAspectSupport中实现的。在createTransactionIfNecessary方法的调用中，会向AbstractTransactionManger执行getTransaction()，这个获取Transaction事务对象的过程，在AbstractTransactionManger实现中需要对事务的情况做出不同的处理，然后，创建一个TransactionStatus，并把这个TransactionStatus设置到对应的TransactionInfo中去，同时将TransactionInfo和当前的线程绑定，从而完成事务的创建过程。调用createTransactionIfNecessary的时序图445.从外部参数读取事务方法调用的事务配置属性，以及使用的PlatformTransactionManger449.如果没有指定名字，使用方法唯一标识来作为事务名458.这个TransactionStatus封装了事务执行的状态信息461.这里使用了定义好的事务方法的配置信息，事务创建由事务处理器来完成，同时返回TransactionStatus来记录当前的事务状态，包括已经创建的事务470.准备TransactionInfo。TransactionInfo对象封装了事务处理的配置信息以及TransactionStatus491.这里为TransactionInfo设置TransactionStatus，这个TransactionStatus很重要，它持有管理事务处理需要的数据，比如，transaction对象就是由TransactionStatus来持有的。504.这里把当前的TransacctionInfo与线程绑定，同时在TransactionInfo中由一个变量来保存以前的TransactionInfo，这样就持有了一连串与事务处理相关的TransactionInfo，虽然不一定需要创建新的事务，但是总会在请求事务时创建TransactionInfo。 具体的事务创建可以交给事务处理器来完成。在事务的创建过程中，已经为事务的管理做好了准备，包括记录事务处理状态，以及绑定事务信息和线程等。createTransactionIfNecessary()方法中的tm.getTransaction(txAttr)调用触发，生成一个TransactionStatus对象，封装了底层事务对象的创建。可以看到，AbstractionPlatformTransactionManager提供了创建事务的模板。AbstractPlatformTransactionManager会根据事务属性配置和当前进程绑定的事务信息，对事务是否需要创建，怎样创建进行一些通用的处理，然后把事务创建的底层工作交给具体的事务处理器完成。尽管具体的事务处理器完成事务创建的过程各不相同，但是不同的事务处理器对事务属性和当前进程事务信息的处理都是相同的。341.这个doGetTransaction()是抽象函数，Transaction对象的取得由具体的事务处理器实现，比如DataSourceTransactionManager344.缓存debug标志位346.如果没有设置事务属性，那么使用默认的事务属性DefaultTransactionDefinition。关于这个DefaultTransactionDefinition，在前面编程式使用事务处理的时候遇到过。这个DefaultTransactionDefinition的默认事务处理属性是：propagationBehivor = PROPAGATION_REQUIRED；isolationLevel=ISOLATION_DEFAULT；timeout=TIMEOUT_DEFAULT;readOnly=false351.检查当前线程是否已经存在事务，如果已经存在事务，那么需要根据在事务属性中定义的事务传播属性配置来处理事务的产生（handleExistingTransaction()）。353.这里对当前线程中已经有事务存在的情况进行处理，结果封装在TransactionStatus中。357.检查事务属性中timeout的设置是否合理361.当前没有事务存在，这是需要根据事务属性设置来创建事务，这里会看到对事务传播属性设置的处理，比如mandatory、required、required_new、nested等。377.这里是创建事务的调用，构造transaction，包括设置ConnectionHolder、隔离级别、timeout。如果是新连接，绑定到当前线程。由具体的事务处理器完成，比如HibernateTransactionManager和DataSourceTransactionManager等。在后面DataSourceTransactionManager的说明中会进一步讲解。379.返回TransactionStatus封装事务执行情况，默认getTransactionSynchronization = SYNCHRONIZATION_ALWAYS，所以在这种情况下，newSynchronization为true391.创建TransactionStatus，但是没有transaction对象，因为在newTransactionStatus中对应于transaction的参数是null流程梳理： 事务创建的结果是生成一个TransactionStatus对象，通过这个对象来保存事务处理需要的基本信息，这个对象与前面提到过的TransactionInfo对象联系在一起，TransactionStatus是TransactionInfo的一个属性，然后会把TransactionInfo保存在ThreadLocal对象里，这样当前线程可以通过ThreadLocal对象取得TransactionInfo，以及与这个事务对应的TransactionStatus对象，从而把事务的处理信息与调用事务方法的当前线程绑定起来。528.这里判断是不是新事务，如果是新事务，那么需要把事务属性存放到当前线程中。TransactionSynchronizationManager维护一系列的ThreadLocal变量来保持事务属性，比如并发事务隔离级别，是否有活跃的事务等。530.这里是把结果记录在DefaultTransactionStatus中返回。 新事务的创建是比较好理解的，这里需要根据事务属性配置进行创建。所谓创建，首先是把创建工作交给具体的事务处理器来完成，比如DataSourceTransactionManager，把创建的事务对象在TransactionStatus中保存下来，然后将其他的事务属性和线程ThreadLocal变量进行绑定。","categories":[],"tags":[]},{"title":"也谈HashMap实现原理","slug":"也谈HashMap实现原理","date":"2019-02-17T06:20:53.000Z","updated":"2019-02-17T10:57:00.938Z","comments":true,"path":"2019/02/17/也谈HashMap实现原理/","link":"","permalink":"http://yoursite.com/2019/02/17/也谈HashMap实现原理/","excerpt":"","text":"HashMap在互联网应用中是一个老生常谈的话题。从redis等各类缓存到spring内部BeanDefinition的存储，都能看到HashMap的身影。可见hashMap这个数据结构的重要性。最近也在重看HashMap的结构，记录一下，希望能有一些启发。 不同版本的JDK,HashMap的实现略有不同，以下是JDK1.8版本的HashMap。用intelliJ打开HashMap源码，打开Structure视图,可以看到HashMap主体存储结构是1234567/** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */transient Node&lt;K,V&gt;[] table; Node是HashMap的一个静态内部类，以下是Node结构的定义123456789101112static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; Node结构中的next字段指向的是下一个Node节点，所以简单来说，HashMap是一个桶型的结构,如图其中，数组是基本结构，数组中存储的是链表。而HashMap的查找顺序是首先按照hash值，找到数组中的链表，然后遍历这个链表，通过key对象的equals方法逐一进行比对。 再来看一下主要的几个字段1234final float loadFactor; //table的负载因子，负载因子越高，table的填充率越高static final float DEFAULT_LOAD_FACTOR = 0.75f; //table负载因子默认是0.75transient int size; //map中的k-v键值对数量int threshold; //容纳k-v对的极限，如果超过这个值，就会扩容 看主要的初始化方法123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; 可以看到，这里并没有对table分配内存空间，分配的内存操作放在put方法中，这里要注意tableSizeFor(initialCapacity)这个方法，源码如下：123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 可以看到，这里用了一个位运算，无符号右移，最终的作用就是输出不小于cap的首个2的n次幂，作为table的初始大小。至于为什么HashMap的数组长度要用2的n次幂，这个后面会有讲解。","categories":[],"tags":[]},{"title":"yilia主题的hexo如何集成gitalk评论插件","slug":"yilia主题的hexo如何集成gitalk评论插件","date":"2019-02-11T08:20:20.000Z","updated":"2019-02-11T11:15:06.382Z","comments":true,"path":"2019/02/11/yilia主题的hexo如何集成gitalk评论插件/","link":"","permalink":"http://yoursite.com/2019/02/11/yilia主题的hexo如何集成gitalk评论插件/","excerpt":"","text":"gitalk是一个利用Github API,基于Github issue和Preact开发的评论插件，使用github账号登录,支持markdown语法,和hexo集成也比较简单 阅读这篇文章的朋友注意了，本文是基于yilia主题的hexo，如果是其他主题，可能配置会有一些差异 第一、首先需要在github上新建一个OAuth Apps，方法是在右上角头像下的settings-&gt;developer settings新建 第二、在hexo安装目录的\\themes\\yilia\\layout_partial\\post文件夹中新建gitalk.ejs,代码如下12345678910111213141516&lt;div class=&quot;gitalk&quot;&gt; &lt;div id=&quot;gitalk-container&quot;&gt;&lt;/div&gt; &lt;script src=&quot;/lib/md5/md5.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; const gitalk = new Gitalk(&#123; clientID: &apos;&lt;%=theme.gitalk.client_id%&gt;&apos;, clientSecret: &apos;&lt;%=theme.gitalk.client_secret%&gt;&apos;, repo: &apos;&lt;%=theme.gitalk.repo%&gt;&apos;, owner: &apos;&lt;%=theme.gitalk.owner%&gt;&apos;, admin: &apos;&lt;%=theme.gitalk.admin%&gt;&apos;, id: md5(location.pathname), // Ensure uniqueness and length less than 50 distractionFreeMode: false // Facebook-like distraction free mode &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt;&lt;/div&gt; 其中clientID和clientSecret是上一步注册OAuth Apps后得到的key和secretrepo是存放评论的仓库名，owner和admin是你github的登录名注意这里id有一个md5的函数(这是一个坑，后面会说明)，需要引入1&lt;script src=&quot;/lib/md5/md5.min.js&quot;&gt;&lt;/script&gt; 这个md5的js可以从github上搜索下载到，存放路径是主题source文件夹下，例如hexo\\themes\\yilia\\source\\lib 第三、在hexo\\themes\\yilia\\layout_partial\\article.ejs文件后加上1234567&lt;% if (!index &amp;&amp; theme.gitalk.enable &amp;&amp; post.comments)&#123; %&gt;&lt;%- partial(&apos;post/gitalk&apos;, &#123; key: post.slug, title: post.title, url: config.url+url_for(post.path) &#125;) %&gt;&lt;% &#125; %&gt; 其中post/gitalk是gitalk.ejs文件的相对路径 最后、修改根目录下的_config.yml，在最后加上123456789# 注释所有畅言配置# 配置gitalkgitalk: enable: true client_id: 你申请的clientId client_secret: 你申请的clientSecret repo: 博客仓库的名称 owner: &apos;你github的用户名&apos; admin: &apos;你github的用户名&apos; 最后的最后，重新发布hexo即可 至于上面第二步为啥要加上md5函数，是因为用原始的id，会因为文章名称过长，导致gitalk初始化失败登陆后显示Error: Validation Failed.同时无法进行评论，评论框可以编辑 网页错误信息如下12345Failed to load resource: the server responded with a status of 422 (Unprocessable Entity)gitalk.jsx:127 err: Error: Request failed with status code 422 at e.exports (https://unpkg.com/gitalk@1.2.2/dist/gitalk.min.js:1:34270) at e.exports (https://unpkg.com/gitalk@1.2.2/dist/gitalk.min.js:19:1283) at XMLHttpRequest.h.(anonymous function) (https://unpkg.com/gitalk@1.2.2/dist/gitalk.min.js:1:33269) 另外，如果根目录下_config.yml中的repo参数不对，打开评论页面后会报Error:Not Found错误","categories":[],"tags":[{"name":"博客","slug":"博客","permalink":"http://yoursite.com/tags/博客/"}]},{"title":"JAVA垃圾回收相关专题的总结","slug":"JAVA垃圾回收相关专题的总结","date":"2019-02-11T06:18:39.000Z","updated":"2019-02-11T06:18:39.847Z","comments":true,"path":"2019/02/11/JAVA垃圾回收相关专题的总结/","link":"","permalink":"http://yoursite.com/2019/02/11/JAVA垃圾回收相关专题的总结/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"遇到线上服务器Full GC怎么办?","slug":"遇到线上服务器Full-GC怎么办","date":"2019-02-11T06:16:01.000Z","updated":"2019-02-11T06:16:01.190Z","comments":true,"path":"2019/02/11/遇到线上服务器Full-GC怎么办/","link":"","permalink":"http://yoursite.com/2019/02/11/遇到线上服务器Full-GC怎么办/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"记一次线上异常的排查和定位","slug":"记一次线上异常的排查和定位","date":"2019-02-09T12:30:02.000Z","updated":"2019-02-09T15:50:43.191Z","comments":true,"path":"2019/02/09/记一次线上异常的排查和定位/","link":"","permalink":"http://yoursite.com/2019/02/09/记一次线上异常的排查和定位/","excerpt":"","text":"某段时间，线上服务不时会爆出dwr数据异常。初步断定是后端接口返回异常所致。 由于当时我们的服务已经接入ELK，所以第一时间登录kibana后台，按照lucene语法搜索（Tag:”study_online”） AND (message:”exception”)，定位到服务器的异常 异常信息(由于当时的异常日志已经被冲掉了，这是我从网上摘录的)：1234567891011121314java.lang.IllegalStateException: Timed out waiting to add Cmd: 1 Opaque: 1147840 Key: com.stubhub.user.business.entity.UserSession|63C21A07311389A1EC361D834BF46E72 Cas: 0 Exp: 7200 Flags: 1 Data Length: 1748(max wait=10000ms) at net.spy.memcached.protocol.TCPMemcachedNodeImpl.addOp(TCPMemcachedNodeImpl.java:362) at net.spy.memcached.MemcachedConnection.addOperation(MemcachedConnection.java:1267) at com.couchbase.client.CouchbaseConnection.addOperation(CouchbaseConnection.java:277) at net.spy.memcached.MemcachedConnection.enqueueOperation(MemcachedConnection.java:1185) at net.spy.memcached.MemcachedClient.asyncStore(MemcachedClient.java:328) at net.spy.memcached.MemcachedClient.set(MemcachedClient.java:929) at com.stubhub.common.cache.store.couchbase.CouchbaseStore.put(CouchbaseStore.java:148) at com.stubhub.common.cache.store.CompositeCacheStore.put(CompositeCacheStore.java:69) at com.stubhub.common.session.impl.UserSessionCacheManagerImpl.putCrossModuleValue(UserSessionCacheManagerImpl.java:48) at com.stubhub.user.business.manager.impl.UserSessionCacheMgrImpl.putUserSessionToStore(UserSessionCacheMgrImpl.java:269) at com.stubhub.user.business.manager.impl.UserSessionCacheMgrImpl.createUserSession(UserSessionCacheMgrImpl.java:806) at sun.reflect.GeneratedMethodAccessor1305.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) 从日志中判断是因为memcached超时抛出的异常。首先查看工程的memcached设置，代码如下123456789101112131415161718192021222324&lt;bean id=&quot;memcachedClient&quot; class=&quot;com.xxx.xxx.cache.impl.KeyPrefixSupportedMemcachedClientFactory&quot;&gt; &lt;property name=&quot;servers&quot; value=&quot;$&#123;memcached_address_list&#125;&quot; /&gt; &lt;property name=&quot;namespace&quot; value=&quot;study_&quot; /&gt; &lt;property name=&quot;protocol&quot; value=&quot;BINARY&quot; /&gt; &lt;property name=&quot;transcoder&quot;&gt; &lt;bean class=&quot;net.spy.memcached.transcoders.SerializingTranscoder&quot;&gt; &lt;property name=&quot;compressionThreshold&quot; value=&quot;16384&quot; /&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;maxReconnectDelay&quot; value=&quot;60&quot; /&gt; &lt;property name=&quot;opTimeout&quot; value=&quot;200&quot;/&gt; &lt;property name=&quot;opQueueMaxBlockTime&quot; value=&quot;400&quot;/&gt; &lt;property name=&quot;timeoutExceptionThreshold&quot; value=&quot;20&quot;/&gt; &lt;property name=&quot;hashAlg&quot;&gt; &lt;value type=&quot;net.spy.memcached.DefaultHashAlgorithm&quot;&gt;KETAMA_HASH&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;locatorType&quot;&gt; &lt;value type=&quot;net.spy.memcached.ConnectionFactoryBuilder.Locator&quot;&gt;CONSISTENT&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;failureMode&quot;&gt; &lt;value type=&quot;net.spy.memcached.FailureMode&quot;&gt;Redistribute&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;useNagleAlgorithm&quot; value=&quot;false&quot; /&gt;&lt;/bean&gt; 可以看到超时时间opTimeout设置的是200毫秒，而opQueueMaxBlockTime是400毫秒opTimeout是操作超时时间，opQueueMaxBlockTime是指操作的最大阻塞时间。那究竟是哪个时间超时导致的呢？可以通过下载memcacheClient源码，搜索“Timed out waiting to add”定位到如下源码12345678910111213141516171819202122232425/* * (non-Javadoc) * * @see net.spy.memcached.MemcachedNode#addOp(net.spy.memcached.ops.Operation) */public final void addOp(Operation op) &#123; try &#123; if (!authLatch.await(1, TimeUnit.SECONDS)) &#123; op.cancel(); getLogger().warn(&quot;Operation canceled because authentication &quot; + &quot;or reconnection and authentication has &quot; + &quot;taken more than one second to complete.&quot;); getLogger().debug(&quot;Canceled operation %s&quot;, op.toString()); return; &#125; if (!inputQueue.offer(op, opQueueMaxBlockTime, TimeUnit.MILLISECONDS)) &#123; throw new IllegalStateException(&quot;Timed out waiting to add &quot; + op + &quot;(max wait=&quot; + opQueueMaxBlockTime + &quot;ms)&quot;); &#125; &#125; catch (InterruptedException e) &#123; // Restore the interrupted status Thread.currentThread().interrupt(); throw new IllegalStateException(&quot;Interrupted while waiting to add &quot; + op); &#125;&#125; 从源码中可以知晓，原因是inputQueue.offer没有正常返回导致的，超过了opQueueMaxBlockTime的时间限制 知道了原因，下面就开始思考怎么解决吧","categories":[],"tags":[{"name":"debug","slug":"debug","permalink":"http://yoursite.com/tags/debug/"}]},{"title":"Markdown基本语法","slug":"Markdown基本语法","date":"2019-02-09T10:32:02.000Z","updated":"2019-02-09T12:51:20.911Z","comments":true,"path":"2019/02/09/Markdown基本语法/","link":"","permalink":"http://yoursite.com/2019/02/09/Markdown基本语法/","excerpt":"","text":"一、标题1234567语法# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题 示例 这是一级标题这是二级标题这是三级标题这是四级标题这是五级标题这是六级标题二、字体12345语法**这是加粗的文字***这是倾斜的文字*`***这是斜体加粗的文字***~~这是加删除线的文字~~ 示例这是加粗的文字这是倾斜的文字`这是斜体加粗的文字这是加删除线的文字 三、引用1234语法&gt;这是引用的内容&gt;&gt;这是引用的内容&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;这是引用的内容 示例 这是引用的内容 这是引用的内容 这是引用的内容 四、分割线12345语法-------******** 示例 五、图片1234语法：![图片alt](图片地址 &apos;&apos;图片title&apos;&apos;)图片alt就是显示在图片下面的文字，相当于对图片内容的解释。图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 示例 六、超链接123语法：[超链接名](超链接地址 &quot;超链接title&quot;)title可加可不加 示例：简书百度 七、列表 无序列表 12语法：无序列表用 - + * 任何一种都可以 有序列表 12语法：数字加点 例如1.列表内容2.列表内容3.列表内容 列表嵌套 一级无序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级无序列表内容 1.二级有序列表内容 2.二级有序列表内容 3.二级有序列表内容 1.一级有序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 2.一级有序列表内容 1.二级有序列表内容 2.二级有序列表内容 3.二级有序列表内容 八、表格123456789101112语法：表头|表头|表头---|:--:|---:内容|内容|内容内容|内容|内容第二行分割表头和内容。- 有一个就行，为了对齐，多加了几个文字默认居左-两边加：表示文字居中-右边加：表示文字居右注：原生的语法两边都要用 | 包起来。此处省略 示例：表头|表头|表头—|:–:|—:内容|内容|内容内容|内容|内容 九、代码语法：单行代码：代码之间分别用一个反引号包起来create table user;代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行123代码...代码...代码...","categories":[],"tags":[{"name":"个人博客","slug":"个人博客","permalink":"http://yoursite.com/tags/个人博客/"}]}]}